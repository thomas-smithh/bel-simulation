{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simulation as sim\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy import stats\n",
    "from scipy.stats import skewnorm\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.stats import skewnorm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trials = pd.read_pickle('BEL_trials_14_Optimising_with_initial_probing_lumenvolcost_fccstart_pos.pkl')\n",
    "#trials = pd.read_pickle('BEL_trials_15_Optimising_with_initial_probing_lumenvolcost_fccstart_pos_goodrangeonly.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_and_run_simulation(\n",
    "    run_number\n",
    "):\n",
    "    simulation = sim.Simulation(N_bodies=70)\n",
    "\n",
    "    beta = random.uniform(1,200) # this was initially optimised to 1-> 400\n",
    "    alpha = 0.3 # this was initially optimised to 0.000078 -> 0.5\n",
    "    A_eq_star_scaling = random.uniform(0.000111,0.4)\n",
    "    P_star = 1 # this was initially optimised to 0.1 -> 1.1\n",
    "    radius_scaling = random.uniform(0.5, 1.8)\n",
    "    volume_scaling = 0.1 #in initial optimisiation this was 0.01 -> 0.1\n",
    "\n",
    "    simulation.execute(\n",
    "        beta=beta,\n",
    "        alpha=alpha,\n",
    "        A_eq_star_scaling=A_eq_star_scaling,\n",
    "        P_star=P_star,\n",
    "        radius_scaling=radius_scaling,\n",
    "        volume_scaling = volume_scaling,\n",
    "        write_results=True,\n",
    "        # max_reset_count=20,\n",
    "        run_number=run_number,\n",
    "        write_path=\"f:\\\\Bel_Simulation\\\\Outputs_no_optimisation_good_range_70init_0p1vol_Pstar_alphafixed_1in20_std\"\n",
    "        )\n",
    "\n",
    "    return simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation = instantiate_and_run_simulation(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "My Simulation:   0%|          | 566/1000000 [6:01:14<10631:08:42, 38.29s/it] \n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A result has failed to un-serialize. Please ensure that the objects returned by the function are always picklable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\Tom\\anaconda3\\envs\\bel_simulation\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 661, in wait_result_broken_or_wakeup\n    result_item = result_reader.recv()\n                  ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Tom\\anaconda3\\envs\\bel_simulation\\Lib\\multiprocessing\\connection.py\", line 250, in recv\n    buf = self._recv_bytes()\n          ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Tom\\anaconda3\\envs\\bel_simulation\\Lib\\multiprocessing\\connection.py\", line 334, in _recv_bytes\n    return self._get_more_data(ov, maxsize)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Tom\\anaconda3\\envs\\bel_simulation\\Lib\\multiprocessing\\connection.py\", line 356, in _get_more_data\n    ov, err = _winapi.ReadFile(self._handle, left, overlapped=True)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nMemoryError\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sim\u001b[38;5;241m.\u001b[39mtqdm_joblib(tqdm(desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMy Simulation\u001b[39m\u001b[38;5;124m\"\u001b[39m, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1_000_000\u001b[39m)) \u001b[38;5;28;01mas\u001b[39;00m progress_bar:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstantiate_and_run_simulation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m2313\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1_000_000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Tom\\anaconda3\\envs\\bel_simulation\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Tom\\anaconda3\\envs\\bel_simulation\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tom\\anaconda3\\envs\\bel_simulation\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tom\\anaconda3\\envs\\bel_simulation\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Tom\\anaconda3\\envs\\bel_simulation\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Tom\\anaconda3\\envs\\bel_simulation\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A result has failed to un-serialize. Please ensure that the objects returned by the function are always picklable."
     ]
    }
   ],
   "source": [
    "with sim.tqdm_joblib(tqdm(desc=\"My Simulation\", total=1_000_000)) as progress_bar:\n",
    "    Parallel(n_jobs=5)(delayed(instantiate_and_run_simulation)(j+2313) for j in range(1_000_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_gaussian(x, mu, sigma):\n",
    "    max_val = 1 / (sigma * np.sqrt(2 * np.pi))\n",
    "    pdf_val = (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma) ** 2)\n",
    "    y = pdf_val / max_val\n",
    "    return y\n",
    "\n",
    "class ScaledSkewNormal:\n",
    "\n",
    "    def __init__(self, a, mu, sigma):\n",
    "        neg_pdf = lambda x: -skewnorm.pdf(x, a, mu, sigma)\n",
    "        self.result = minimize_scalar(neg_pdf, bounds=(mu - 3*sigma, mu + 3*sigma), method='bounded')\n",
    "        self.pdf_max_value = skewnorm.pdf(self.result.x, a, mu, sigma)\n",
    "        self.a = a\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def get_value(self, x):\n",
    "        pdf_val = skewnorm.pdf(x, self.a, self.mu, self.sigma)\n",
    "        return pdf_val / self.pdf_max_value\n",
    "\n",
    "def lumen_vol_dist(x):\n",
    "    if 0 <= x <= 0.5:\n",
    "        return 1\n",
    "    elif 0.5 < x <= 1:\n",
    "        return -2 * x + 2\n",
    "    else:\n",
    "        return 1e-30\n",
    "\n",
    "def time_dist(x):\n",
    "    return (x / 15) + 1e-30\n",
    "\n",
    "def lumen_com_dist(x):\n",
    "    return 1 / np.exp(0.5*x)\n",
    "\n",
    "def derive_target(\n",
    "    mean_separation: float,\n",
    "    lumen_com: float,\n",
    "    sphericity: float,\n",
    "    n_cells: float,\n",
    "    lumen_vol: float,\n",
    "    hull_vol: float,\n",
    "    max_time: float\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Derive the value to be maximised from the results of the simulation.\n",
    "    \n",
    "    Inputs:\n",
    "        results: The results of the simulation.\n",
    "    \n",
    "    Returns:\n",
    "        The value to be maximised.\n",
    "    \"\"\"\n",
    "\n",
    "    #skew_normal_volume = ScaledSkewNormal(5, -50, 500)\n",
    "    skew_normal_n_cells = ScaledSkewNormal(5, -80, 500)\n",
    "    skew_normal_sphericity = ScaledSkewNormal(-5, 1.05, 0.3)\n",
    "    \n",
    "    lumen_com_optimisation_values = lumen_com_dist(lumen_com)\n",
    "    mean_separation_optimisation_value = scaled_gaussian(mean_separation, mu=-0.2, sigma=0.3)\n",
    "    #volume_optimisation_value = skew_normal_n_cells.get_value(volume)\n",
    "    sphericity_optimisation_value = skew_normal_sphericity.get_value(sphericity)\n",
    "    n_cells_optimisation_value = skew_normal_n_cells.get_value(n_cells)\n",
    "    lumen_vol_optimisation_value = lumen_vol_dist(lumen_vol/hull_vol)\n",
    "    time_optimisation_value = time_dist(max_time)\n",
    "\n",
    "    target_value = (\n",
    "        mean_separation_optimisation_value *\n",
    "        #volume_optimisation_value *\n",
    "        sphericity_optimisation_value *\n",
    "        n_cells_optimisation_value *\n",
    "        lumen_vol_optimisation_value *\n",
    "        time_optimisation_value *\n",
    "        lumen_com_optimisation_values\n",
    "    )\n",
    "\n",
    "    return target_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation = instantiate_and_run_simulation(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = simulation.results.iloc[-1]\n",
    "target = -derive_target(\n",
    "    results['mean_separation'],\n",
    "    results['lumen_distance_from_com'],\n",
    "    results['sphericity'],\n",
    "    results['final_N_bodies'],\n",
    "    results['lumen_volume'],\n",
    "    results['hull_volume'],\n",
    "    results['t']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6481651365106207"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([pd.read_parquet(f\"C:\\\\Users\\\\Tom\\\\Documents\\\\Bel PhD\\\\Bel_Simulation\\\\outputs\\\\{i}\") for i in os.listdir(\"C:\\\\Users\\\\Tom\\\\Documents\\\\Bel PhD\\\\Bel_Simulation\\\\outputs\") if i.endswith(\".parquet\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation = sim.Simulation(N_bodies=50, timestep_reset=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002725328356610611"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.mean(simulation.positions, axis=0)-simulation.positions[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002725328356610611"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.mean(simulation.positions, axis=0)- simulation.positions[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bel_simulation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
